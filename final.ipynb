{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMM/TxWf7RDGIdYH0HqsxR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyhuang7215/2021VRDL-final/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "CgJCu6dMP5tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install mmcv & [mmclassfication](https://github.com/open-mmlab/mmclassification)\n"
      ],
      "metadata": {
        "id": "B5Irl9IqP9lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html &> /dev/null\n",
        "!pip install git+https://github.com/open-mmlab/mim.git &> /dev/null\n",
        "!mim install mmcls &> /dev/null"
      ],
      "metadata": {
        "id": "j7f7V54HP7av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/open-mmlab/mmclassification.git &> /dev/null\n",
        "%cd mmclassification\n",
        "!pip install -e . &> /dev/null"
      ],
      "metadata": {
        "id": "hz13RSER8rDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the cropped data"
      ],
      "metadata": {
        "id": "lasnG2vOgAlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown==4.2.0 &> /dev/null\n",
        "!mkdir crop\n",
        "%cd crop\n",
        "!gdown https://drive.google.com/uc?id=1-21kEFvSJ6KrQSdD0-PdID-CIsVz0uCP\n",
        "!gdown https://drive.google.com/uc?id=1-2ZyTHaRLCa5RbnclqaGrf0eZ4_RQRxf\n",
        "!gdown https://drive.google.com/uc?id=1-2Ukm8-bQJZNejDvytqQeop6FoFMOqUS\n",
        "!unzip train_crop.zip &> /dev/null\n",
        "!unzip test_st1.zip &> /dev/null\n",
        "!unzip test_st2.zip &> /dev/null\n",
        "%cd .. "
      ],
      "metadata": {
        "id": "63-84JK4Hd_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the train/test imgs from kaggle"
      ],
      "metadata": {
        "id": "Ro6ViCpDgD0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "# Fill in your kaggle info\n",
        "api_token = {\"username\":\"kent7215\",\"key\":\"3065ba9573cd023aab1f637f1fae793e\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir dataset\n",
        "%cd dataset\n",
        "!kaggle competitions download -c the-nature-conservancy-fisheries-monitoring\n",
        "!unzip train.zip &> /dev/null\n",
        "!unzip test_stg1.zip &> /dev/null\n",
        "!7z x ./test_stg2.7z &> /dev/null\n",
        "!gdown https://drive.google.com/uc?id=1YtUoLWseXUQfBQ_G7_NSbXj-lFPxBqJZ\n",
        "%cd .."
      ],
      "metadata": {
        "id": "CzqHbk_E-OEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the checkpoints and configs"
      ],
      "metadata": {
        "id": "SrUxXNe4gXDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1ShJcNI2mwj39sGj5DF-yZIEDWzQbeXuB? -O ./ --folder"
      ],
      "metadata": {
        "id": "XcMSXDmOgWPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may download the pretrained model and train by yourself"
      ],
      "metadata": {
        "id": "tDVTAc_Rf2cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir checkpoints\n",
        "# !wget -c https://download.openmmlab.com/mmclassification/v0/swin-transformer/swin_small_224_b16x64_300e_imagenet_20210615_110219-7f9d988b.pth \\\n",
        "#       -O checkpoints/pretrained_small.pth\n",
        "# !wget -c https://download.openmmlab.com/mmclassification/v0/resnest/resnest101_imagenet_converted-032caa52.pth \\\n",
        "#       -O checkpoints/pretrained2.pth\n",
        "# !wget -c https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth \\\n",
        "#        -O checkpoints/resnet_pretrained.pth\n",
        "# !python tools/train final/swin.py"
      ],
      "metadata": {
        "id": "inTBuTdoEVdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import warnings\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import torch\n",
        "from mmcv.parallel import collate, scatter\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmcls.datasets.pipelines import Compose\n",
        "from mmcls.models import build_classifier\n",
        "from mmcls.apis import inference_model, init_model, show_result_pyplot\n",
        "\n",
        "\n",
        "def my_inference_model(model, img):\n",
        "    \"\"\"Inference image(s) with the classifier.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The loaded classifier.\n",
        "        img (str/ndarray): The image filename or loaded image.\n",
        "\n",
        "    Returns:\n",
        "        result (dict): The classification results that contains\n",
        "            `class_name`, `pred_label` and `pred_score`.\n",
        "    \"\"\"\n",
        "    cfg = model.cfg\n",
        "    device = next(model.parameters()).device  # model device\n",
        "    # build the data pipeline\n",
        "    if isinstance(img, str):\n",
        "        if cfg.data.test.pipeline[0]['type'] != 'LoadImageFromFile':\n",
        "            cfg.data.test.pipeline.insert(0, dict(type='LoadImageFromFile'))\n",
        "        data = dict(img_info=dict(filename=img), img_prefix=None)\n",
        "    else:\n",
        "        if cfg.data.test.pipeline[0]['type'] == 'LoadImageFromFile':\n",
        "            cfg.data.test.pipeline.pop(0)\n",
        "        data = dict(img=img)\n",
        "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
        "    data = test_pipeline(data)\n",
        "    data = collate([data], samples_per_gpu=1)\n",
        "    if next(model.parameters()).is_cuda:\n",
        "        # scatter to specified GPU\n",
        "        data = scatter(data, [device])[0]\n",
        "\n",
        "    # forward the model\n",
        "    with torch.no_grad():\n",
        "        scores = model(return_loss=False, **data)\n",
        "        pred_score = np.max(scores, axis=1)[0]\n",
        "        pred_label = np.argmax(scores, axis=1)[0]\n",
        "        result = {'pred_label': pred_label, 'pred_score': float(pred_score)}\n",
        "    result['pred_class'] = model.CLASSES[result['pred_label']]\n",
        "    return scores[0]"
      ],
      "metadata": {
        "id": "72hH5KhAelpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv(model, csv_name, test_prefix):\n",
        "    with open(csv_name, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['image', 'ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n",
        "\n",
        "    folder = os.path.join(test_prefix, 'test_stg1')\n",
        "    imgs = os.listdir(folder)\n",
        "    imgs.sort()\n",
        "    with open(csv_name, 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for img in imgs:\n",
        "            result = list(my_inference_model(model, os.path.join(folder, img)))\n",
        "            result.insert(0, img)\n",
        "            writer.writerow(result)\n",
        "\n",
        "    folder = os.path.join(test_prefix, 'test_stg2')\n",
        "    imgs = os.listdir(folder)\n",
        "    imgs.sort()\n",
        "    with open(csv_name, 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for img in imgs:\n",
        "            result = list(my_inference_model(model, os.path.join(folder, img)))\n",
        "            result.insert(0, 'test_stg2/' + img)\n",
        "            writer.writerow(result)"
      ],
      "metadata": {
        "id": "tLtZsrbVb8I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the result of each model (It may take about an hour)"
      ],
      "metadata": {
        "id": "IlnVHQDHgpGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = 'final/swin.py'\n",
        "checkpoint_file = 'final/swin.pth'\n",
        "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
        "write_csv(model, 'swin.csv', 'dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVLLg5DZBZ2Z",
        "outputId": "ddbce540-136d-47dc-842d-1afc153c5f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: final/swin.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = 'final/resnest101.py'\n",
        "checkpoint_file = 'final/resnest101.pth'\n",
        "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
        "write_csv(model, 'resnest.csv', 'dataset')"
      ],
      "metadata": {
        "id": "RGNUafpuBcZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = 'final/swin.py'\n",
        "checkpoint_file = 'final/swin_crop.pth'\n",
        "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
        "write_csv(model, 'swin_crop.csv', 'crop')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clvrABPwCnEf",
        "outputId": "a5c60671-8dd6-4c52-a4e4-b69128205f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: final/swin_crop.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do model ensembling, save result into final.csv"
      ],
      "metadata": {
        "id": "N6x-K1rDgfAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble(a, b, c):\n",
        "    a = np.array(a).astype(np.float)\n",
        "    b = np.array(b).astype(np.float)\n",
        "    c = np.array(c).astype(np.float)\n",
        "    output = (a + b + c) / 3\n",
        "    return list(output)\n",
        "\n",
        "\n",
        "def read_csv(csv_name):\n",
        "    with open(csv_name, 'r') as f:\n",
        "        pred = list(csv.reader(f))\n",
        "    return pred\n",
        "\n",
        "output1 = read_csv('swin.csv')\n",
        "output2 = read_csv('resnest.csv')\n",
        "output3 = read_csv('swin_crop.csv')\n",
        "\n",
        "\n",
        "with open('final.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['image', 'ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n",
        "    for i, (a, b, c) in enumerate(zip(output1, output2, output3)):\n",
        "        if i == 0:\n",
        "            continue\n",
        "        result = ensemble(a[1:], b[1:], c[1:])\n",
        "        result.insert(0, a[0])\n",
        "        writer.writerow(result)"
      ],
      "metadata": {
        "id": "3vh6mf8tJtdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}